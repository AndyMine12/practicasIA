{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QbrsyMTz9-JK"
   },
   "source": [
    "# Importación de Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H7eRAXp9-Jnj"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F0fdtan580er"
   },
   "source": [
    "# Carga y Visualización de Datos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lq8nVxnb84sQ"
   },
   "outputs": [],
   "source": [
    "# NOTE. Remember to load CSV onto Colab environment\n",
    "daily_dataframe = pd.read_csv('SN_d_tot_V2.0.csv', sep=\",\")\n",
    "monthly_dataframe = pd.read_csv('SN_m_tot_V2.0.csv', sep=\",\")\n",
    "smooth_dataframe = pd.read_csv('SN_ms_tot_V2.0.csv', sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q8HJpAhC_3Do"
   },
   "outputs": [],
   "source": [
    "# Describe data\n",
    "print(\"DAILY\")\n",
    "daily_dataframe.info()\n",
    "print(\"\\n\\nMONTHLY\")\n",
    "monthly_dataframe.info()\n",
    "print(\"\\n\\nSMOOTH MONTHLY\")\n",
    "smooth_dataframe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jwM5r1BHE1cp"
   },
   "outputs": [],
   "source": [
    "# Graph data\n",
    "graph_dict:dict = {\"Year\":[], \"Month\":[], \"Fraction\":[], \"Sunspots\":[], \"Deviation\":[], \"Measures\":[], \"Indicator\":[], \"Type\":[]}\n",
    "types = [\"Monthly (Raw)\", \"Monthly (Smooth)\"]\n",
    "for index, row in daily_dataframe.iterrows():\n",
    "  graph_dict[\"Year\"].append(row[\"Year\"])\n",
    "  graph_dict[\"Month\"].append(row[\"Month\"])\n",
    "  graph_dict[\"Fraction\"].append(row[\"Fraction\"])\n",
    "  graph_dict[\"Sunspots\"].append(row[\"Sunspots\"])\n",
    "  graph_dict[\"Deviation\"].append(row[\"Deviation\"])\n",
    "  graph_dict[\"Measures\"].append(row[\"Measures\"])\n",
    "  graph_dict[\"Indicator\"].append(row[\"Indicator\"])\n",
    "  graph_dict[\"Type\"].append(\"Daily\")\n",
    "for frame_tuple in zip(monthly_dataframe.iterrows(),smooth_dataframe.iterrows()):\n",
    "  zip_row = []\n",
    "  zip_row.append(frame_tuple[0][1])\n",
    "  zip_row.append(frame_tuple[1][1])\n",
    "  for item in zip(types,zip_row):\n",
    "    graph_dict[\"Year\"].append(item[1][\"Year\"])\n",
    "    graph_dict[\"Month\"].append(item[1][\"Month\"])\n",
    "    graph_dict[\"Fraction\"].append(item[1][\"Fraction\"])\n",
    "    graph_dict[\"Sunspots\"].append(item[1][\"Sunspots\"])\n",
    "    graph_dict[\"Deviation\"].append(item[1][\"Deviation\"])\n",
    "    graph_dict[\"Measures\"].append(item[1][\"Measures\"])\n",
    "    graph_dict[\"Indicator\"].append(item[1][\"Indicator\"])\n",
    "    graph_dict[\"Type\"].append(item[0])\n",
    "graph_dataframe = pd.DataFrame(graph_dict)\n",
    "seaborn.lineplot(data=graph_dataframe,x=\"Fraction\",y=\"Sunspots\", hue=\"Type\", palette=[\"#000088\",\"#99FF00\",\"#FF0000\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w3pw8arYKf3H"
   },
   "outputs": [],
   "source": [
    "# Graph only after 1900's, and before Jan 2024, and before Jan 2024\n",
    "partial_graph_dataframe = graph_dataframe[graph_dataframe.Fraction > 1900]\n",
    "partial_graph_dataframe = partial_graph_dataframe[partial_graph_dataframe.Fraction <= 2024]\n",
    "partial_graph_dataframe = partial_graph_dataframe[partial_graph_dataframe.Fraction <= 2024]\n",
    "seaborn.lineplot(data=partial_graph_dataframe,x=\"Fraction\",y=\"Sunspots\", hue=\"Type\", palette=[\"#000088\",\"#99FF00\",\"#FF0000\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Pdo3L4Z8-VG"
   },
   "source": [
    "# Modelo Keras - Recurrente Simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MBmkSM919Trw"
   },
   "outputs": [],
   "source": [
    "import keras as kr\n",
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN, Dense, LSTM, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bBQZCSHpFrV_"
   },
   "outputs": [],
   "source": [
    "sequence_length = 5\n",
    "\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(units= 5, input_shape= (sequence_length, 1), activation= \"tanh\"))\n",
    "model.add(Dense(units= 1, activation= \"tanh\"))\n",
    "\n",
    "model.compile(loss= \"mean_squared_error\", optimizer= \"adam\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "adr6KzInjee4"
   },
   "source": [
    "## Reformateando los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7_TGxjy0mVpq"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "def normalize_data(df: pd.DataFrame, interval_top: float = 0.9, interval_bottom: float = -0.9) -> tuple[pd.DataFrame, float, float]:\n",
    "  sunspot_data: list[float] = []\n",
    "  for sunspot in df[\"Sunspots\"]:\n",
    "    if sunspot != -1:\n",
    "      sunspot_data.append(sunspot)\n",
    "\n",
    "  data_max: float = max(sunspot_data)\n",
    "  data_min: float = min(sunspot_data)\n",
    "  denom: float = data_max - data_min\n",
    "  diff: float = interval_top - interval_bottom\n",
    "  normalized_df = df.copy()\n",
    "  # print(normalized_dataframe)\n",
    "  with warnings.catch_warnings():\n",
    "    warnings.simplefilter(action='ignore')\n",
    "    for index, row in df.iterrows():\n",
    "      if row[\"Sunspots\"] != -1:\n",
    "        normalized_df[\"Sunspots\"][index] = (((row[\"Sunspots\"] - data_min)/(denom))*(diff)) + interval_bottom\n",
    "\n",
    "  return normalized_df, data_max, data_min\n",
    "\n",
    "def split_data(df:pd.DataFrame, time_steps:int = 12) -> tuple[np.ndarray, np.ndarray, list[float]]:\n",
    "  data_multilist: list[list[float]] = []\n",
    "  tag_list: list[float] = []\n",
    "  year_fraction_list: list[float] = []\n",
    "  current: list[float] = []\n",
    "  for index, row in df.iterrows():\n",
    "    if len(current) == time_steps:\n",
    "      tag_list.append(row[\"Sunspots\"])\n",
    "      year_fraction_list.append(row[\"Fraction\"])\n",
    "      data_multilist.append(np.array(current))\n",
    "      current = current[1:] #Remove first element\n",
    "    # if row[\"Sunspots\"] != -1:\n",
    "    current.append((row[\"Sunspots\"]))\n",
    "  return np.array(data_multilist), np.array(tag_list), year_fraction_list\n",
    "\n",
    "# print(monthly_dataframe)\n",
    "normalized_dataframe, data_max, data_min = normalize_data(daily_dataframe)\n",
    "\n",
    "data_X, data_labels, data_years = split_data(normalized_dataframe, sequence_length)\n",
    "\n",
    "# print(data_labels)\n",
    "from math import floor\n",
    "\n",
    "separator = floor(len(data_X)*0.7)\n",
    "\n",
    "train_X, train_labels = data_X[: separator], data_labels[: separator]\n",
    "test_X, test_labels, test_years = data_X[separator :], data_labels[separator :], data_years[separator :]\n",
    "# print(train_labels)\n",
    "# print(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "inbavg9Tpjru"
   },
   "outputs": [],
   "source": [
    "model.fit(train_X, train_labels, batch_size= 50, epochs= 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dn_JXKFwtsz8"
   },
   "outputs": [],
   "source": [
    "predict_labels = model.predict(test_X)\n",
    "\n",
    "# print(predict_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MwUdxndbzi--"
   },
   "outputs": [],
   "source": [
    "def denormalize_labels(labels: np.ndarray, true_max: float, true_min: float) -> np.ndarray:\n",
    "  denormalized_labels: list[float] = []\n",
    "  current_max: float = max(labels)\n",
    "  current_min: float = min(labels)\n",
    "  denom: float = current_max - current_min\n",
    "  diff: float = true_max - true_min\n",
    "  for label in labels:\n",
    "    denormalized_labels.append((((label - current_min)/(denom))*diff) + true_min)\n",
    "  return np.array(denormalized_labels)\n",
    "\n",
    "from matplotlib import pyplot\n",
    "\n",
    "denormalized_predicts = denormalize_labels(predict_labels, data_max, data_min)\n",
    "denormalized_labels = denormalize_labels(test_labels, data_max, data_min)\n",
    "\n",
    "# pyplot.plot(test_years, predict_labels, color= 'red')\n",
    "# pyplot.plot(test_years, test_labels, color= 'blue')\n",
    "pyplot.ylim([0, 80])\n",
    "pyplot.xlim([2018, 2020])\n",
    "pyplot.plot(test_years, denormalized_predicts, color= 'red')\n",
    "pyplot.plot(test_years, denormalized_labels, color= 'blue')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yEIwLUWYmXI9"
   },
   "outputs": [],
   "source": [
    "relative_error: float = 0.0\n",
    "\n",
    "for prediction, value in zip(denormalized_predicts, denormalized_labels):\n",
    "  # print(f\"{prediction} | {value}\")\n",
    "  relative_error += (abs(prediction - value)/(max(prediction, value, 0.0001)))*100\n",
    "\n",
    "print(f\"Error relativo: {relative_error/len(denormalized_labels)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Bjj0mmpFS4P"
   },
   "source": [
    "## Monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lbVSJHOuFWSt"
   },
   "outputs": [],
   "source": [
    "monthly_sequence_length = 4\n",
    "\n",
    "monthly_model = Sequential()\n",
    "monthly_model.add(SimpleRNN(units= 6, input_shape= (monthly_sequence_length, 1), activation= \"tanh\"))\n",
    "monthly_model.add(Dense(units= 1, activation= \"tanh\"))\n",
    "\n",
    "monthly_model.compile(loss= \"mean_squared_error\", optimizer= \"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uhrOpGHeFwu1"
   },
   "outputs": [],
   "source": [
    "# print(monthly_dataframe)\n",
    "monthly_normalized_dataframe, monthly_data_max, monthly_data_min = normalize_data(monthly_dataframe)\n",
    "\n",
    "monthly_data_X, monthly_data_labels, monthly_data_years = split_data(monthly_normalized_dataframe, monthly_sequence_length)\n",
    "\n",
    "# print(data_labels)\n",
    "# from math import floor\n",
    "\n",
    "separator = floor(len(monthly_data_X)*0.7)\n",
    "\n",
    "monthly_train_X, monthly_train_labels = monthly_data_X[: separator], monthly_data_labels[: separator]\n",
    "monthly_test_X, monthly_test_labels, monthly_test_years = monthly_data_X[separator :], monthly_data_labels[separator :], monthly_data_years[separator :]\n",
    "# print(train_labels)\n",
    "# print(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X66-fbLsGyva"
   },
   "outputs": [],
   "source": [
    "monthly_model.fit(monthly_train_X, monthly_train_labels, batch_size= 3, epochs= 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TgJDa9nzG-a4"
   },
   "outputs": [],
   "source": [
    "predict_labels = monthly_model.predict(monthly_test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6YXZ4wu4HD6b"
   },
   "outputs": [],
   "source": [
    "denormalized_predicts = denormalize_labels(predict_labels, data_max, data_min)\n",
    "denormalized_labels = denormalize_labels(monthly_test_labels, data_max, data_min)\n",
    "\n",
    "# pyplot.plot(test_years, predict_labels, color= 'red')\n",
    "# pyplot.plot(test_years, test_labels, color= 'blue')\n",
    "pyplot.ylim([0, 80])\n",
    "pyplot.xlim([2018, 2020])\n",
    "pyplot.plot(monthly_test_years, denormalized_predicts, color= 'red')\n",
    "pyplot.plot(monthly_test_years, denormalized_labels, color= 'blue')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9FettFYhHZWC"
   },
   "outputs": [],
   "source": [
    "relative_error: float = 0.0\n",
    "\n",
    "for prediction, value in zip(denormalized_predicts, denormalized_labels):\n",
    "  # print(f\"{prediction} | {value}\")\n",
    "  relative_error += (abs(prediction - value)/(max(prediction, value, 0.0001)))*100\n",
    "\n",
    "print(f\"Error relativo: {relative_error/len(denormalized_labels)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HNVxQtls9CyG"
   },
   "source": [
    "# Modelo Keras - LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VREiguFsoqrY"
   },
   "source": [
    "## Reformatear los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "Co6i2Pqc9TCh"
   },
   "outputs": [],
   "source": [
    "def to_LSTM_format(df:pd.DataFrame, time_steps:int = 12) -> tuple[np.ndarray, np.ndarray]:\n",
    "  data_multilist: list[np.ndarray] = []\n",
    "  tag_list: list[float] = []\n",
    "  current: list[float] = []\n",
    "  for index, row in df.iterrows():\n",
    "    if len(current) == time_steps:\n",
    "      tag_list.append(row[\"Sunspots\"])\n",
    "      data_multilist.append(np.array(current))\n",
    "      current = current[1:] #Remove first element\n",
    "    current.append(row[\"Sunspots\"])\n",
    "  return np.array(data_multilist), np.array(tag_list)\n",
    "\n",
    "time_steps = 14\n",
    "LSTM_train_dataframe = daily_dataframe[daily_dataframe.Sunspots != -1]\n",
    "LSTM_train_dataframe = LSTM_train_dataframe[LSTM_train_dataframe.Fraction < 2014]\n",
    "LSTM_train_data, LSTM_train_tags = to_LSTM_format(LSTM_train_dataframe)\n",
    "for index, zip_item in enumerate(zip(LSTM_train_data, LSTM_train_tags)):\n",
    "  dataiter, tagiter = zip_item\n",
    "  print(index, \"\\t-->\\t\", dataiter, \"\\t|| \", tagiter)\n",
    "  if index >= 20:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-wH8nFzDvurZ"
   },
   "outputs": [],
   "source": [
    "# Construct LSTM network\n",
    "LSTM_model = Sequential()\n",
    "LSTM_model.add(kr.Input(shape=(14,1)))\n",
    "LSTM_model.add(LSTM(8, return_sequences = False))\n",
    "LSTM_model.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
    "LSTM_model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "LSTM_model.fit(LSTM_train_data, LSTM_train_tags, epochs=80, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "ZrIaJddczsP5"
   },
   "outputs": [],
   "source": [
    "validate_dataframe = daily_dataframe[daily_dataframe.Fraction >= 2014]\n",
    "validate_dataframe = validate_dataframe[validate_dataframe.Fraction <= 2024]\n",
    "\n",
    "LSTM_validation_data, LSTM_validation_tags = to_LSTM_format(validate_dataframe)\n",
    "LSTM_prediction = LSTM_model.predict(LSTM_validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6JGfnR_QOhOL"
   },
   "outputs": [],
   "source": [
    "graph_dict:dict = {\"Fraction\":[], \"Sunspots\":[], \"Type\":[]}\n",
    "mean_rel_error:float = 0\n",
    "for item in zip(validate_dataframe.iterrows(), LSTM_validation_tags, LSTM_prediction):\n",
    "  index, row = item[0] #Extract index and row from dataframe iterrows\n",
    "  for elem in zip([item[1], item[2][0]], [\"Expected\", \"Real\"]): #Unwrap value from prediction's resulting ndarray\n",
    "    graph_dict[\"Fraction\"].append(row[\"Fraction\"])\n",
    "    graph_dict[\"Sunspots\"].append(elem[0])\n",
    "    graph_dict[\"Type\"].append(elem[1])\n",
    "  mean_rel_error += (1/len(LSTM_prediction)) * np.abs( (item[1] - item[2]) / np.maximum(item[1],item[2]) ) # Calculated as real value minus expected value, divided by expected value\n",
    "mean_rel_error = mean_rel_error[0] #Unwrap value from ndarray\n",
    "\n",
    "# Show error\n",
    "print(\"Mean Relative Error -->\", mean_rel_error)\n",
    "# Graph\n",
    "LSTM_graph_dataframe = pd.DataFrame(graph_dict)\n",
    "seaborn.lineplot(data=LSTM_graph_dataframe,x=\"Fraction\",y=\"Sunspots\", hue=\"Type\", palette=[\"#000088\",\"#99FF00\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a97t_ARG9HWw"
   },
   "source": [
    "# Análisis Hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kG-ACkE89SnL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KIkO-XCD9Ohh"
   },
   "source": [
    "# Comparación Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pGHt7a9q9R81"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
