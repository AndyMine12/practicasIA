{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZGudLGXJAkG"
      },
      "source": [
        "# Red Neuronal para Clasificación no Lineal"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#I don't think this is needed for this one; !pip install ipympl"
      ],
      "metadata": {
        "collapsed": true,
        "id": "gNgs2DwYSclN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "FHyvnjYaJAkH"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import random\n",
        "import math\n",
        "import seaborn\n",
        "from _collections_abc import Callable\n",
        "from google.colab import output\n",
        "\n",
        "# I think we won't use this, this time\n",
        "# %matplotlib inline\n",
        "# %matplotlib widget\n",
        "# output.enable_custom_widget_manager()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxIifSyEJAkI"
      },
      "source": [
        "Cree los datos de entrada y sus etiquetas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "cn2rarW_JAkI",
        "outputId": "fea1b201-9c0a-4e0e-8eda-d91231a88176",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: xlabel='x', ylabel='y'>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "#Generate and split data\n",
        "full_data = [((0,0),0),((0,1),1), ((1,0),1), ((1,1),0)]\n",
        "random.shuffle(full_data)\n",
        "train_data = full_data[:3] #Obtener los primeros 3 elementos (~75% de data)\n",
        "validation_data = full_data[3:] #Obtener el resto: 1 elemento (~25% de data)\n",
        "\n",
        "#Assign training data and their tags\n",
        "X = [data[0] for data in train_data]\n",
        "y = [data[1] for data in train_data]\n",
        "\n",
        "#Show generated data\n",
        "# Get full data\n",
        "data_dict:dict = {\"x\":[], \"y\":[], \"label\":[], \"group\":[]}\n",
        "for item in train_data:\n",
        "  data_dict[\"x\"].append(item[0][0])\n",
        "  data_dict[\"y\"].append(item[0][1])\n",
        "  data_dict[\"label\"].append(item[1])\n",
        "  data_dict[\"group\"].append(\"train\")\n",
        "for item in validation_data:\n",
        "  data_dict[\"x\"].append(item[0][0])\n",
        "  data_dict[\"y\"].append(item[0][1])\n",
        "  data_dict[\"label\"].append(item[1])\n",
        "  data_dict[\"group\"].append(\"validation\")\n",
        "# Graph\n",
        "seaborn.scatterplot(data=pd.DataFrame(data_dict),x=\"x\",y=\"y\",hue=\"label\", style=\"group\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjEl_O9LJAkI"
      },
      "source": [
        "Abstracción de Red Neuronal\n",
        "\n",
        "Capa de Red Feedforward"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Hto2hDMIJAkI"
      },
      "outputs": [],
      "source": [
        "#Models a whole hidden layer of a feedforward network\n",
        "class feedforward_layer:\n",
        "  def __init__(self, entry_data_size:int, neurons:int, activation_func:Callable[[float],float], derivated_activation_func:Callable[[float],float]):\n",
        "    self.neurons:int = neurons\n",
        "    self.activation_func:Callable[[float],float] = activation_func\n",
        "    self.derivated_activation_func:Callable[[float],float] = derivated_activation_func\n",
        "    self.weights:list[list[float]] = []\n",
        "    self.biases:list[float] = []\n",
        "    for i in range(neurons):\n",
        "      neuron_weight = []\n",
        "      for j in range(entry_data_size):\n",
        "        neuron_weight.append(1 - 2*random.random())\n",
        "      self.weights.append(neuron_weight)\n",
        "      self.biases.append(0)\n",
        "    self.Z:list[float] = None #Argument of the activation function\n",
        "    self.A:list[float] = None #Layer output\n",
        "\n",
        "  def forward_pass(self, prev_output:list[float]) -> list[float]:\n",
        "    self.Z = []\n",
        "    self.A = []\n",
        "    for item in zip(self.weights,self.biases):\n",
        "      neuron_weight = item[0]\n",
        "      neuron_z = 0\n",
        "      for elem in zip(prev_output, neuron_weight):\n",
        "        neuron_z += elem[1]*elem[0]\n",
        "      neuron_z += item[1] #Add the neuron's bias\n",
        "      self.Z.append(neuron_z)\n",
        "      self.A.append(self.activation_func(neuron_z))\n",
        "    return self.A\n",
        "\n",
        "  @property\n",
        "  def get_weights(self) -> list[list[float]]:\n",
        "    return self.weights.copy()\n",
        "  @property\n",
        "  def output(self) -> list[float]:\n",
        "    return self.A.copy()\n",
        "\n",
        "  def self_delta(self, next_weights:list[list[float]], next_delta:np.ndarray, gradient_value:np.ndarray)->np.ndarray:\n",
        "    W_array = np.array(next_weights)\n",
        "    delta_prop = np.matmul(W_array.T, next_delta)\n",
        "    delta = delta_prop * gradient_value\n",
        "    return delta\n",
        "\n",
        "  def backpropagation(self, learn_rate:float, prev_output:list[float], next_weights:list[list[float]], next_delta:np.ndarray, gradient_value:np.ndarray) -> None:\n",
        "    delta_T = (self.self_delta(next_weights, next_delta, gradient_value)).T\n",
        "    adjust_matrix = learn_rate * delta_T\n",
        "\n",
        "    new_weights = []\n",
        "    for item in zip(self.weights, np.matmul(adjust_matrix, np.array(prev_output))):\n",
        "      neuron_weight = []\n",
        "      for elem in zip(item[0], item[1]):\n",
        "        neuron_weight.append(elem[0] - elem[1])\n",
        "      new_weights.append(neuron_weight)\n",
        "    self.weights = new_weights\n",
        "\n",
        "    new_biases = []\n",
        "    for item in zip(self.biases, adjust_matrix):\n",
        "      new_biases.append(item[0] - item[1])\n",
        "    self.biases = new_biases\n",
        "\n",
        "#Models the entry layer of the network, sets activation function as identity so that the data is not modified on entry\n",
        "class input_feedforward_layer(feedforward_layer):\n",
        "  def __init__(self, entry_data_size:int):\n",
        "    super().__init__(entry_data_size, entry_data_size, lambda x: x, lambda x: 0)\n",
        "\n",
        "  def backpropagation(self, learn_rate:float, prev_output:list[float], next_weights:list[list[float]], next_delta:np.ndarray, gradient_value:np.ndarray) -> None:\n",
        "    pass\n",
        "\n",
        "#Models the output layer of the network\n",
        "class output_feedforward_layer(feedforward_layer):\n",
        "  @property\n",
        "  def gradient(self)->np.ndarray:\n",
        "    gradient = []\n",
        "    for item in self.Z:\n",
        "      gradient.append(self.derivated_activation_func(item))\n",
        "    return np.array(gradient)\n",
        "\n",
        "  def self_delta(self, expected_values:list[float])->np.ndarray:\n",
        "    error_matrix:list[float] = []\n",
        "    for item in zip(expected_values, self.A):\n",
        "      error_matrix.append(item[0] - item[1])\n",
        "    delta = []\n",
        "    for item in zip(error_matrix, self.gradient):\n",
        "      delta.append(item[0] * item[1])\n",
        "    return np.array(delta)\n",
        "\n",
        "  def backpropagation(self, expected_values:list[float], learn_rate:float, prev_output:list[float]) -> None:\n",
        "    delta_T = (self.self_delta(expected_values)).T\n",
        "    adjust_matrix = learn_rate * delta_T\n",
        "\n",
        "    new_weights = []\n",
        "    for item in zip(self.weights, np.matmul(adjust_matrix, np.array(prev_output))):\n",
        "      neuron_weight = []\n",
        "      for elem in zip(item[0], item[1]):\n",
        "        neuron_weight.append(elem[0] - elem[1])\n",
        "      new_weights.append(neuron_weight)\n",
        "    self.weights = new_weights\n",
        "\n",
        "    new_biases = []\n",
        "    for item in zip(self.biases, adjust_matrix):\n",
        "      new_biases.append(item[0] - item[1])\n",
        "    self.biases = new_biases\n",
        "\n",
        "#Models the feedforward network / \"Multilayer Perceptron\"\n",
        "class feedforward_network:\n",
        "  def __init__(self, network_structure:list[int], activation_functions:list[Callable[[float],float]], derivated_activation_functions:list[Callable[[float],float]], tolerance = np.power(10.0, -5)):\n",
        "    self.layers: list[feedforward_layer] = []\n",
        "    self.tolerance: float = tolerance\n",
        "\n",
        "    prevLayerSize:int = 0\n",
        "    for item in enumerate(network_structure, 1): #Start enumeration at index = 1\n",
        "      if item[0] == 1:\n",
        "        self.layers.append(input_feedforward_layer(item[1]))\n",
        "        self.entry_size:int = item[1]\n",
        "      elif ( item[0] < len(network_structure) ):\n",
        "        self.layers.append(feedforward_layer(prevLayerSize, item[1], activation_functions[item[0] - 2], derivated_activation_functions[item[0] - 2]))\n",
        "      else:\n",
        "        self.layers.append(output_feedforward_layer(prevLayerSize, item[1], activation_functions[item[0] - 2], derivated_activation_functions[item[0] - 2]))\n",
        "        self.output_size:int = item[1]\n",
        "      prevLayerSize = item[1]\n",
        "\n",
        "  @property\n",
        "  def get_entry_size(self) -> int:\n",
        "    return self.entry_size\n",
        "  @property\n",
        "  def get_output_size(self) -> int:\n",
        "    return self.output_size\n",
        "\n",
        "  def predict(self, data:list[list[float]]) -> list[list[float]]:\n",
        "    output:list[list[float]] = []\n",
        "    for item in data:\n",
        "      prev_output:list[float] = item\n",
        "      for layer in self.layers:\n",
        "        prev_output = layer.forward_pass(prev_output)\n",
        "      output.append(prev_output)\n",
        "    return output\n",
        "\n",
        "  #Trains the model for the desired number of epochs, returns a list of (index, error) per-epoch\n",
        "  def train(self, train_data:list[list[float]], tags:list[list[float]], learn_rate:float, epochs:int = 200, printEach:int = None) -> list[tuple[int,float]]:\n",
        "    errorList:list[tuple[int,float]] = []\n",
        "    acc:int = 0\n",
        "    big_acc:int = 1\n",
        "    for i in range(epochs):\n",
        "      errorAvg:float = 0\n",
        "      #Train with all data each epoch\n",
        "      for data, tag in zip(train_data,tags):\n",
        "        #Do forward-pass\n",
        "        output:list[float] = data\n",
        "        for layer in self.layers:\n",
        "          output = layer.forward_pass(output)\n",
        "\n",
        "        #Calculate partial error\n",
        "        error:float = 0\n",
        "        for value in zip(output, tag):\n",
        "          error += (1/(2*len(tag))) * np.power(value[0] - value[1], 2)\n",
        "        errorAvg += (1/len(tags)) * error\n",
        "\n",
        "        #Do backpropagation\n",
        "        for index, layer in enumerate(reversed(self.layers),0):\n",
        "          gradient:list[float] = None\n",
        "          prev_delta:np.ndarray = None\n",
        "          prev_output:list[float] = self.layers[-2 - index].output\n",
        "\n",
        "          if (index == 0): #The current layer is the output layer\n",
        "            gradient = layer.gradient\n",
        "            prev_delta = layer.self_delta(tag)\n",
        "            layer.backpropagation(tag, learn_rate, prev_output)\n",
        "          elif (index < len(self.layers) - 1): #The current layer is a hidden layer\n",
        "            layer.backpropagation(learn_rate, prev_output, self.layers[index+1].weights, prev_delta, gradient)\n",
        "            prev_delta = layer.self_delta(self.layers[index+1].weights, prev_delta, gradient)\n",
        "          #The input layer does not require backpropagation\n",
        "      #Add error of current epoch to list\n",
        "      errorList.append( (i+1, errorAvg) )\n",
        "\n",
        "      #If desired, print progress when iteration reached\n",
        "      if (printEach is not None):\n",
        "        acc += 1\n",
        "        if (acc >= printEach):\n",
        "          print(f\"Iteration {acc*big_acc} reached\")\n",
        "          big_acc += 1\n",
        "          acc = 0\n",
        "\n",
        "      #Check if tolerance threshold was reached\n",
        "      if (errorAvg < self.tolerance):\n",
        "        break\n",
        "    return errorList\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NoI6Nqd_JAkI"
      },
      "source": [
        "Defina la función de activación y su derivada:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "mPtfxalJJAkI"
      },
      "outputs": [],
      "source": [
        "def sigmoid(x):\n",
        "    # Definicion de la función sigmoide\n",
        "    return 1/(1 + math.exp(-x))\n",
        "\n",
        "def dsigmoid(x):\n",
        "    # Definicion de la derivada de la función sigmoide\n",
        "    return sigmoid(x)*(1 - sigmoid(x))\n",
        "\n",
        "def r_sigmoid_create(r):\n",
        "  return (lambda x: sigmoid(r*x))\n",
        "\n",
        "def r_dsigmoid_create(r):\n",
        "  return (lambda x: dsigmoid(r*x)*r)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lDjldVeJAkJ"
      },
      "source": [
        "## Entrenamiento de la red neuronal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7aErHd4JAkJ"
      },
      "source": [
        "Use el esquema de \"Retropropagación\" para entrenar la red."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "vOW3d27xJAkJ",
        "outputId": "b7b5b79e-bb51-4296-fddd-c56440ef4c2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.462657972619888], [0.005894290573602485]]\n"
          ]
        }
      ],
      "source": [
        "# Build activation functions\n",
        "activation_functions = [r_sigmoid_create(10), r_sigmoid_create(1000)]\n",
        "# Build derivated functions\n",
        "deriv_activation_functions = [r_dsigmoid_create(10), r_dsigmoid_create(1000)]\n",
        "# Assemble network\n",
        "network = feedforward_network([2,2,1], activation_functions, deriv_activation_functions)\n",
        "\n",
        "# Split train data between data and tags\n",
        "only_data = [ list(item) for item in X]\n",
        "only_tags = [ [item] for item in y]\n",
        "# Train network\n",
        "print(network.predict([[1,2],[1,1]]))\n",
        "#network.train(only_data, only_tags, np.power(10.0, -5), printEach=20)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Merely encapsulating the prediction process\n",
        "# NOTE. Only use after training\n",
        "def predict_data(data:list[tuple[float,float]]) -> list[float]:\n",
        "  global w1, w2, w3, b1, b2, b3\n",
        "  label_list:list[float] = []\n",
        "  for item in data:\n",
        "    result1 = forward_step(list(item), list(w1), b1, sigmoid)\n",
        "    result2 = forward_step(list(item), list(w2), b2, sigmoid)\n",
        "    result3 = forward_step([result1[0], result2[0]], list(w3), b3, sigmoid)\n",
        "    label_list.append(result3[0])\n",
        "  return label_list"
      ],
      "metadata": {
        "id": "8KrnsmPyfaZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLPHrJRUJAkK"
      },
      "source": [
        "Valide del entrenamiento. Con una gráfica del error en funcion de las épocas."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Gráfica Error vs. Épocas\n",
        "grafica = plt.figure().add_subplot()\n",
        "grafica.plot(errorList[0], errorList[1], color = \"red\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RXSZ8NF-c4x0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RN0__w_eJAkK"
      },
      "outputs": [],
      "source": [
        "# Get actual labels\n",
        "x: list[float] = []\n",
        "y: list[float] = []\n",
        "labels: list[float] = []\n",
        "for i in range(0, len(validation_data)):\n",
        "  x.append(validation_data[i][0][0])\n",
        "  y.append(validation_data[i][0][1])\n",
        "  labels.append(validation_data[i][1])\n",
        "\n",
        "# Get predicted labels\n",
        "input_data = [item[0] for item in validation_data]\n",
        "labels_pred : list[float] = predict_data(input_data)\n",
        "\n",
        "# Graph actual versus predictions\n",
        "grafica = plt.figure().add_subplot(projection = \"3d\")\n",
        "grafica.scatter(x, y, labels, color = \"blue\")\n",
        "grafica.scatter(x, y, labels_pred, color = \"red\")\n",
        "plt.show()\n",
        "\n",
        "# Calculate MSE\n",
        "error = 0\n",
        "for item in zip(labels, labels_pred):\n",
        "  error += np.power(item[0] - item[1], 2)\n",
        "error = error / len(labels)\n",
        "print(\"Mean Squared Error\\n\", error)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Support for third party widgets will remain active for the duration of the session. To disable support:"
      ],
      "metadata": {
        "id": "w0Cq1ZF2SuYD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Probando con Keras"
      ],
      "metadata": {
        "id": "NS8ZzyLq8kcd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qUZIxE6MJAkK"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "training_x: list[float] = []\n",
        "training_y: list[float] = []\n",
        "training_labels: list[float] = []\n",
        "\n",
        "\n",
        "from sklearn import preprocessing\n",
        "\n",
        "data = []\n",
        "tag = []\n",
        "for item in train_data:\n",
        "  data.append(item[0])\n",
        "  tag.append(item[1])\n",
        "scaler = preprocessing.StandardScaler().fit(np.array(data))\n",
        "# min_tag = min(tag)\n",
        "# tag = [value - min_tag for value in tag] #Rescale tags for interval [0,1]\n",
        "postprocess = [scaler.transform(np.array(data)), tag]\n",
        "#Refill\n",
        "data = []\n",
        "for value in zip(postprocess[0], postprocess[1]):\n",
        "  data.append( (tuple(value[0]), value[1]) )\n",
        "scaled_train_data = data\n",
        "\n",
        "for i in range(0, len(scaled_train_data)):\n",
        "  training_x.append(scaled_train_data[i][0][0])\n",
        "  training_y.append(scaled_train_data[i][0][1])\n",
        "  training_labels.append(scaled_train_data[i][1])\n",
        "\n",
        "model = keras.Sequential()\n",
        "model.add(layers.Dense(units = 2, activation = \"sigmoid\", input_dim = 2))\n",
        "model.add(layers.Dense(units = 1, activation = \"sigmoid\"))\n",
        "#model.add(keras.Input(shape = (2,)))\n",
        "model.build()\n",
        "#optimizer = keras.optimizers.SGD()\n",
        "model.compile(optimizer = keras.optimizers.SGD(), loss = keras.losses.MeanSquaredError())\n",
        "model.summary()\n",
        "#lst = [np.array(training_x), np.array(training_y)]\n",
        "lst = np.array([np.array(item) for item in zip(training_x, training_y)])\n",
        "lbls = np.array([np.array(item) for item in training_labels])\n",
        "print(np.array(lst).shape)\n",
        "#arr = np.array(lst)\n",
        "\n",
        "\n",
        "model.fit(lst, lbls, epochs = 500)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_lst = np.array([np.array(item) for item in zip(x, y)])\n",
        "\n",
        "predict_lbls = model.predict(eval_lst)"
      ],
      "metadata": {
        "id": "4QSME5H98ujX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grafica = plt.figure().add_subplot(projection = \"3d\")\n",
        "grafica.scatter(x, y, labels, color = \"blue\")\n",
        "grafica.scatter(x, y, predict_lbls, color = 'orange')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GbdYTEOW8zA2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import output\n",
        "output.disable_custom_widget_manager()"
      ],
      "metadata": {
        "id": "FA-iyfjPSuYE"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}